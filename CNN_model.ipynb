{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After hybrid and transformer model, we can take a look at the traditional CNN model which performes really well with sequenced data such as literature and for this case, piano scripts. \n",
    "Fist we can try some simple layers for performance estimate. \n",
    "Structure:\n",
    "Convolutional Layers: 3 convolutional layers with 32, 64, and 128 filters, respectively.\n",
    "Pooling: Max pooling after each convolutional layer.\n",
    "Fully Connected Layers: 2 fully connected layers with 256 and num_classes units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "class PianoDataset(Dataset):\n",
    "    def __init__(self, csv_file, sequence_length=100, augment=False):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.df = pd.concat([self.df.drop('event_type', axis=1), pd.get_dummies(self.df['event_type'], prefix='event_type')], axis=1)\n",
    "        self.df = self.df.astype(np.float32)  # Ensure all data is of type float32\n",
    "        self.sequence_length = sequence_length\n",
    "        self.augment = augment\n",
    "        self.data = self.generate_sequences()\n",
    "\n",
    "    def generate_sequences(self):\n",
    "        input_sequences = []\n",
    "        target_events = []\n",
    "        for i in range(len(self.df) - self.sequence_length):\n",
    "            full_sequence = self.df.iloc[i:i+self.sequence_length+1]\n",
    "            input_sequence = full_sequence.iloc[:-1]\n",
    "            target_event = full_sequence.iloc[-1]\n",
    "            input_sequences.append(input_sequence.values)\n",
    "            target_events.append(target_event.values.argmax())  # Use class index as target\n",
    "        return list(zip(input_sequences, target_events))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence, target = self.data[idx]\n",
    "        if self.augment:\n",
    "            sequence = self.augment_sequence(sequence)\n",
    "        sequence_tensor = torch.tensor(sequence, dtype=torch.float32)\n",
    "        target_tensor = torch.tensor(target, dtype=torch.long)\n",
    "        return sequence_tensor, target_tensor\n",
    "\n",
    "    def augment_sequence(self, sequence):\n",
    "        # Transposition\n",
    "        if random.random() < 0.5:\n",
    "            transpose_amount = random.randint(-5, 5)\n",
    "            sequence[:, 0] += transpose_amount  \n",
    "        \n",
    "        # Time-stretching\n",
    "        if random.random() < 0.5:\n",
    "            stretch_factor = random.uniform(0.8, 1.2)\n",
    "            sequence[:, 1] *= stretch_factor  \n",
    "        \n",
    "        # Adding Noise\n",
    "        if random.random() < 0.5:\n",
    "            noise = np.random.normal(0, 0.01, sequence.shape)\n",
    "            sequence += noise\n",
    "        \n",
    "        return sequence\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3, 3), padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=(3, 3), padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.fc1 = nn.Linear(128 * (input_dim // 8) * (sequence_length // 8), 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  \n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "sequence_length = 100 \n",
    "input_dim = 10  \n",
    "num_classes = 8  \n",
    "model = CNNModel(input_dim, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the CSV file\n",
    "output_csv = 'D:\\\\Projects\\\\Resources\\\\midis_v1.2\\\\Beethoven\\\\Beethoven_note_sequence.csv'\n",
    "\n",
    "# Create dataset and dataloaders\n",
    "full_dataset = PianoDataset(csv_file=output_csv, sequence_length=100, augment=True)\n",
    "\n",
    "def train_valid_test_split(dataset, train_ratio=0.7, valid_ratio=0.15, test_ratio=0.15):\n",
    "    assert train_ratio + valid_ratio + test_ratio == 1, \"Ratios must sum to 1\"\n",
    "    \n",
    "    train_size = int(train_ratio * len(dataset))\n",
    "    valid_size = int(valid_ratio * len(dataset))\n",
    "    test_size = len(dataset) - train_size - valid_size\n",
    "    \n",
    "    train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, valid_size, test_size])\n",
    "    return train_dataset, valid_dataset, test_dataset\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, valid_dataset, test_dataset = train_valid_test_split(full_dataset)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True) \n",
    "valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.1535, Accuracy: 0.5384\n",
      "Validation Loss: 1.0426, Accuracy: 0.5759\n",
      "Starting epoch 2/50\n",
      "Epoch 2/50, Loss: 0.9583, Accuracy: 0.6077\n",
      "Validation Loss: 0.9327, Accuracy: 0.6137\n",
      "Starting epoch 3/50\n",
      "Epoch 3/50, Loss: 0.8868, Accuracy: 0.6330\n",
      "Validation Loss: 0.8777, Accuracy: 0.6375\n",
      "Starting epoch 4/50\n",
      "Epoch 4/50, Loss: 0.8566, Accuracy: 0.6450\n",
      "Validation Loss: 0.8624, Accuracy: 0.6430\n",
      "Starting epoch 5/50\n",
      "Epoch 5/50, Loss: 0.8368, Accuracy: 0.6525\n",
      "Validation Loss: 0.8491, Accuracy: 0.6482\n",
      "Starting epoch 6/50\n",
      "Epoch 6/50, Loss: 0.8209, Accuracy: 0.6597\n",
      "Validation Loss: 0.8411, Accuracy: 0.6513\n",
      "Starting epoch 7/50\n",
      "Epoch 7/50, Loss: 0.8056, Accuracy: 0.6659\n",
      "Validation Loss: 0.8403, Accuracy: 0.6528\n",
      "Starting epoch 8/50\n",
      "Epoch 8/50, Loss: 0.7916, Accuracy: 0.6720\n",
      "Validation Loss: 0.8383, Accuracy: 0.6532\n",
      "Starting epoch 9/50\n",
      "Epoch 9/50, Loss: 0.7761, Accuracy: 0.6790\n",
      "Validation Loss: 0.8447, Accuracy: 0.6518\n",
      "Starting epoch 10/50\n",
      "Epoch 10/50, Loss: 0.7599, Accuracy: 0.6859\n",
      "Validation Loss: 0.8448, Accuracy: 0.6528\n",
      "Starting epoch 11/50\n",
      "Epoch 11/50, Loss: 0.7429, Accuracy: 0.6939\n",
      "Validation Loss: 0.8575, Accuracy: 0.6471\n",
      "Starting epoch 12/50\n",
      "Epoch 12/50, Loss: 0.7253, Accuracy: 0.7022\n",
      "Validation Loss: 0.8635, Accuracy: 0.6449\n",
      "Starting epoch 13/50\n",
      "Epoch 13/50, Loss: 0.7067, Accuracy: 0.7106\n",
      "Validation Loss: 0.8767, Accuracy: 0.6424\n",
      "Early stopping at epoch 13\n",
      "Validation Loss: 0.8341, Accuracy: 0.6533\n",
      "Test Loss: 0.8341, Test Accuracy: 0.6533\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Set device and initialize model and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNModel(input_dim, num_classes).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_model(model, train_loader, valid_loader, optimizer, num_epochs=50, patience=5):\n",
    "    model.train()\n",
    "    best_accuracy = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        print(f'Starting epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            if outputs.shape[0] != targets.shape[0]:\n",
    "                print(f\"Shape mismatch: outputs shape {outputs.shape}, targets shape {targets.shape}\")\n",
    "                continue\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "            total_predictions += targets.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = correct_predictions / total_predictions\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
    "        \n",
    "        val_loss, val_accuracy = evaluate_model(model, valid_loader)\n",
    "        \n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_cnn_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f'Early stopping at epoch {epoch+1}')\n",
    "                break\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "            total_predictions += targets.size(0)\n",
    "    \n",
    "    loss = running_loss / len(data_loader.dataset)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(f'Validation Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "    return loss, accuracy\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, valid_loader, optimizer, num_epochs=50, patience=5)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.load_state_dict(torch.load('best_cnn_model.pth'))\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can tuning some parameter and change the layer to more complex structure for better performance.\n",
    "Structuer:\n",
    "Initial Convolutional Layer: 1 convolutional layer with 64 filters, batch normalization, and max pooling.\n",
    "Residual Blocks: 3 residual blocks with 64 to 128, 128 to 256, and 256 to 512 filters, respectively.\n",
    "Global Average Pooling: Reduces each feature map to a single value.\n",
    "Fully Connected Layers: 2 fully connected layers with 256 and num_classes units.\n",
    "Dropout: Included dropout before the final fully connected layer.\n",
    "And we can see from the result that the performance have been improved decent amount indicating that CNN model handles the sequenced data well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AB\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.0105, Accuracy: 0.5955\n",
      "Validation Loss: 0.9105, Accuracy: 0.6274\n",
      "Starting epoch 2/50\n",
      "Epoch 2/50, Loss: 0.8684, Accuracy: 0.6391\n",
      "Validation Loss: 0.8425, Accuracy: 0.6479\n",
      "Starting epoch 3/50\n",
      "Epoch 3/50, Loss: 0.8321, Accuracy: 0.6541\n",
      "Validation Loss: 0.8305, Accuracy: 0.6533\n",
      "Starting epoch 4/50\n",
      "Epoch 4/50, Loss: 0.8104, Accuracy: 0.6632\n",
      "Validation Loss: 0.8125, Accuracy: 0.6601\n",
      "Starting epoch 5/50\n",
      "Epoch 5/50, Loss: 0.7949, Accuracy: 0.6699\n",
      "Validation Loss: 0.7993, Accuracy: 0.6708\n",
      "Starting epoch 6/50\n",
      "Epoch 6/50, Loss: 0.7810, Accuracy: 0.6765\n",
      "Validation Loss: 0.7915, Accuracy: 0.6733\n",
      "Starting epoch 7/50\n",
      "Epoch 7/50, Loss: 0.7687, Accuracy: 0.6820\n",
      "Validation Loss: 0.7874, Accuracy: 0.6753\n",
      "Starting epoch 8/50\n",
      "Epoch 8/50, Loss: 0.7566, Accuracy: 0.6873\n",
      "Validation Loss: 0.7847, Accuracy: 0.6770\n",
      "Starting epoch 9/50\n",
      "Epoch 9/50, Loss: 0.7443, Accuracy: 0.6924\n",
      "Validation Loss: 0.7890, Accuracy: 0.6743\n",
      "Starting epoch 10/50\n",
      "Epoch 10/50, Loss: 0.7313, Accuracy: 0.6988\n",
      "Validation Loss: 0.7846, Accuracy: 0.6778\n",
      "Starting epoch 11/50\n",
      "Epoch 11/50, Loss: 0.7178, Accuracy: 0.7041\n",
      "Validation Loss: 0.7747, Accuracy: 0.6809\n",
      "Starting epoch 12/50\n",
      "Epoch 12/50, Loss: 0.7024, Accuracy: 0.7111\n",
      "Validation Loss: 0.7816, Accuracy: 0.6814\n",
      "Starting epoch 13/50\n",
      "Epoch 13/50, Loss: 0.6869, Accuracy: 0.7176\n",
      "Validation Loss: 0.7868, Accuracy: 0.6802\n",
      "Starting epoch 14/50\n",
      "Epoch 14/50, Loss: 0.6687, Accuracy: 0.7253\n",
      "Validation Loss: 0.7944, Accuracy: 0.6738\n",
      "Starting epoch 15/50\n",
      "Epoch 15/50, Loss: 0.6492, Accuracy: 0.7340\n",
      "Validation Loss: 0.8024, Accuracy: 0.6747\n",
      "Starting epoch 16/50\n",
      "Epoch 16/50, Loss: 0.6274, Accuracy: 0.7434\n",
      "Validation Loss: 0.8076, Accuracy: 0.6756\n",
      "Starting epoch 17/50\n",
      "Epoch 17/50, Loss: 0.6045, Accuracy: 0.7527\n",
      "Validation Loss: 0.8288, Accuracy: 0.6756\n",
      "Early stopping at epoch 17\n",
      "Validation Loss: 0.7826, Accuracy: 0.6801\n",
      "Test Loss: 0.7826, Test Accuracy: 0.6801\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "class PianoDataset(Dataset):\n",
    "    def __init__(self, data=None, labels=None, csv_file=None, sequence_length=100, augment=False):\n",
    "        if csv_file:\n",
    "            self.df = pd.read_csv(csv_file)\n",
    "            self.df = pd.concat([self.df.drop('event_type', axis=1), pd.get_dummies(self.df['event_type'], prefix='event_type')], axis=1)\n",
    "            self.df = self.df.astype(np.float32)  # Ensure all data is of type float32\n",
    "            self.sequence_length = sequence_length\n",
    "            self.augment = augment\n",
    "            self.data = self.generate_sequences()\n",
    "        else:\n",
    "            self.data = list(zip(data, labels))\n",
    "            self.augment = augment\n",
    "\n",
    "    def generate_sequences(self):\n",
    "        input_sequences = []\n",
    "        target_events = []\n",
    "        for i in range(len(self.df) - self.sequence_length):\n",
    "            full_sequence = self.df.iloc[i:i+self.sequence_length+1]\n",
    "            input_sequence = full_sequence.iloc[:-1]\n",
    "            target_event = full_sequence.iloc[-1]\n",
    "            input_sequences.append(input_sequence.values)\n",
    "            target_events.append(target_event.values.argmax()) \n",
    "        return list(zip(input_sequences, target_events))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence, target = self.data[idx]\n",
    "        if self.augment:\n",
    "            sequence = self.augment_sequence(sequence)\n",
    "        sequence_tensor = torch.tensor(sequence, dtype=torch.float32)\n",
    "        target_tensor = torch.tensor(target, dtype=torch.long)\n",
    "        return sequence_tensor, target_tensor\n",
    "\n",
    "    def augment_sequence(self, sequence):\n",
    "        # Transposition\n",
    "        if random.random() < 0.5:\n",
    "            transpose_amount = random.randint(-5, 5)\n",
    "            sequence[:, 0] += transpose_amount  \n",
    "        \n",
    "        # Time-stretching\n",
    "        if random.random() < 0.5:\n",
    "            stretch_factor = random.uniform(0.8, 1.2)\n",
    "            sequence[:, 1] *= stretch_factor  \n",
    "        \n",
    "        # Adding Noise\n",
    "        if random.random() < 0.5:\n",
    "            noise = np.random.normal(0, 0.01, sequence.shape)\n",
    "            sequence += noise\n",
    "        \n",
    "        return sequence\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=(3, 3), padding=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=padding)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, sequence_length, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        )\n",
    "        self.layer2 = ResidualBlock(64, 128)\n",
    "        self.layer3 = ResidualBlock(128, 256)\n",
    "        self.layer4 = ResidualBlock(256, 512)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "sequence_length = 100  \n",
    "input_dim = 10  \n",
    "num_classes = 8  \n",
    "model = CNNModel(input_dim, sequence_length, num_classes)\n",
    "\n",
    "# Define the path to the CSV file\n",
    "output_csv = 'D:\\\\Projects\\\\Resources\\\\midis_v1.2\\\\Beethoven\\\\Beethoven_note_sequence.csv'\n",
    "\n",
    "# Create dataset and dataloaders\n",
    "full_dataset = PianoDataset(csv_file=output_csv, sequence_length=100, augment=True)\n",
    "\n",
    "def train_valid_test_split(dataset, train_ratio=0.7, valid_ratio=0.15, test_ratio=0.15):\n",
    "    assert train_ratio + valid_ratio + test_ratio == 1, \"Ratios must sum to 1\"\n",
    "    \n",
    "    train_size = int(train_ratio * len(dataset))\n",
    "    valid_size = int(valid_ratio * len(dataset))\n",
    "    test_size = len(dataset) - train_size - valid_size\n",
    "    \n",
    "    train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, valid_size, test_size])\n",
    "    return train_dataset, valid_dataset, test_dataset\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, valid_dataset, test_dataset = train_valid_test_split(full_dataset)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)  \n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Set device and initialize model and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNModel(input_dim, sequence_length, num_classes).to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)  \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_model(model, train_loader, valid_loader, optimizer, num_epochs=50, patience=5):\n",
    "    model.train()\n",
    "    best_accuracy = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        print(f'Starting epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            if outputs.shape[0] != targets.shape[0]:\n",
    "                print(f\"Shape mismatch: outputs shape {outputs.shape}, targets shape {targets.shape}\")\n",
    "                continue\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "            total_predictions += targets.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = correct_predictions / total_predictions\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
    "        \n",
    "        val_loss, val_accuracy = evaluate_model(model, valid_loader)\n",
    "        \n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_cnn_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f'Early stopping at epoch {epoch+1}')\n",
    "                break\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "            total_predictions += targets.size(0)\n",
    "    \n",
    "    loss = running_loss / len(data_loader.dataset)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(f'Validation Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "    return loss, accuracy\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, valid_loader, optimizer, num_epochs=50, patience=5)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.load_state_dict(torch.load('best_cnn_model.pth'))\n",
    "test_loss, test_accuracy = evaluate_model(model, test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasons for Performance Improvement\n",
    "Residual Blocks:\n",
    "\n",
    "Ease of Training: Residual blocks help mitigate the vanishing gradient problem, making it easier to train deeper networks. They allow gradients to flow through the network more effectively during backpropagation.\n",
    "Learning Complex Patterns: By enabling the network to bypass certain layers, residual blocks allow the model to learn complex patterns more efficiently.\n",
    "Batch Normalization:\n",
    "\n",
    "Stabilizing Training: Batch normalization normalizes the inputs to each layer, which helps stabilize and accelerate training by reducing internal covariate shift.\n",
    "Regularization Effect: It has a slight regularization effect, reducing the need for other forms of regularization like dropout.\n",
    "Global Average Pooling:\n",
    "\n",
    "Parameter Reduction: Global average pooling reduces the number of parameters before the fully connected layers, which helps prevent overfitting.\n",
    "Spatial Information: It captures the spatial information by averaging each feature map, which can be beneficial for recognizing patterns in the input data.\n",
    "Increased Depth:\n",
    "\n",
    "Feature Extraction: Increasing the depth of the network allows it to extract more detailed and abstract features from the input data, which can improve performance.\n",
    "Dropout:\n",
    "\n",
    "Preventing Overfitting: Dropout helps prevent overfitting by randomly dropping units during training, which forces the network to learn more robust features.\n",
    "Reasons for Marginal Performance Improvement\n",
    "Data Quality and Quantity:\n",
    "\n",
    "Limited Data: If the dataset is small or not diverse enough, the model might not benefit significantly from increased complexity. The improvements in architecture might not be fully realized without sufficient data.\n",
    "Data Quality: Noisy or low-quality data can limit the model's ability to learn effectively, regardless of the architecture improvements.\n",
    "Model Complexity:\n",
    "\n",
    "Overfitting: Adding more layers and parameters increases the risk of overfitting, especially if the dataset is not large enough to support the increased complexity.\n",
    "Diminishing Returns: Beyond a certain point, adding more layers or complexity does not necessarily translate to better performance. There are diminishing returns as the model might already capture most of the patterns present in the data.\n",
    "Hyperparameter Tuning:\n",
    "\n",
    "Suboptimal Hyperparameters: The performance gain from architectural changes can be limited if the hyperparameters (learning rate, batch size, etc.) are not well-tuned for the new architecture.\n",
    "Training Time and Resources: Deeper and more complex models require more computational resources and time to train, which might limit the extent of hyperparameter tuning.\n",
    "Task Complexity:\n",
    "\n",
    "Nature of the Task: The specific task of processing piano note sequences might not benefit as much from deeper or more complex architectures compared to other tasks like image recognition. The inherent complexity of the task plays a role in determining the effectiveness of model modifications.\n",
    "Implementation Details:\n",
    "\n",
    "Initial Weights and Training Dynamics: The initial weights and the dynamics of training (such as the optimizer used and the learning rate schedule) can also impact the effectiveness of the modifications. Small changes in these aspects can lead to varying degrees of performance improvement.\n",
    "Conclusion\n",
    "While the modifications (residual blocks, batch normalization, global average pooling, increased depth, and dropout) are theoretically and practically sound for improving a CNN's performance, the actual improvement observed can be marginal due to factors like data quality, model complexity, hyperparameter tuning, task-specific characteristics, and implementation details. To achieve significant performance gains, it is essential to carefully balance these factors and consider further experimentation with different architectures, data augmentation techniques, and hyperparameter optimization methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
